{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB_4ImfAeT9Y"
      },
      "source": [
        "# Face Recognition w/ 3D Landmarks\n",
        "\n",
        "Melisa Mete, 150200316\n",
        "\n",
        "Öykü Eren, 150200326\n",
        "\n",
        "Bora Boyacıoğlu, 150200310\n",
        "\n",
        "## Step 2: Model Implementation and Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySx23YjpeT9f"
      },
      "source": [
        "Import necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeNcSfPdeT9g"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2J-1rRtzeT9i"
      },
      "outputs": [],
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUSQF6Sjfp1E"
      },
      "source": [
        "Load Torch device."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QvNkw1jeT9i",
        "outputId": "96f7174c-26b4-40ec-e631-c377a269ff43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UscRWrX4fjK6"
      },
      "source": [
        "### 2.1. Open the Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIIH3bxKezqm"
      },
      "outputs": [],
      "source": [
        "# Change this if running on drive.\n",
        "on_drive = True\n",
        "home_dir = ''\n",
        "model_dir = ''\n",
        "\n",
        "if on_drive:\n",
        "    home_dir = '/content/drive/MyDrive/CVProject/'\n",
        "    model_dir = home_dir + 'model/'\n",
        "    sys.path.append(home_dir + 'model/utils')\n",
        "\n",
        "data_dir = home_dir + data_dir\n",
        "\n",
        "from utils.model import GhostFaceNetsV2\n",
        "from utils.face_dataset import FaceDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o92FoOBaeT9k"
      },
      "outputs": [],
      "source": [
        "# Data paths.\n",
        "train_paths= [data_dir + 'X1_train.npy',\n",
        "              data_dir + 'X2_train.npy',\n",
        "              data_dir + 'y_train.npy']\n",
        "\n",
        "test_paths = [data_dir + 'X1_test.npy',\n",
        "              data_dir + 'X2_test.npy',\n",
        "              data_dir + 'y_test.npy']\n",
        "\n",
        "# Create the datasets.\n",
        "train_dataset = FaceDataset(*train_paths)\n",
        "test_dataset = FaceDataset(*test_paths)\n",
        "\n",
        "# Create data loaders.\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHBW707Sffvj"
      },
      "source": [
        "### 2.2. Initialise the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xaEwsSoeT9k"
      },
      "outputs": [],
      "source": [
        "# Define the model parameters.\n",
        "size = train_dataset.size()\n",
        "length = len(train_dataset)\n",
        "width = 1\n",
        "dropout = 0.3\n",
        "\n",
        "# Model type: Combined, Landmark or Image.\n",
        "combined = 'Combined'\n",
        "\n",
        "# Other parameters.\n",
        "lr = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yxj6NP9feT9l"
      },
      "outputs": [],
      "source": [
        "# Create the model.\n",
        "model = GhostFaceNetsV2(image_size=size, num_classes=length, width=width, dropout=dropout, combined=combined)\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj9voz63fsV9"
      },
      "source": [
        "### 2.3. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaO-Vo1ceT9l"
      },
      "outputs": [],
      "source": [
        "# Training loop parameters.\n",
        "num_epochs = 10\n",
        "epoch = 0\n",
        "timestamp = dt.now().strftime('%d_%H_%M')\n",
        "!mkdir -p {model_dir}model/{timestamp}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGYy8K-QeT9m"
      },
      "outputs": [],
      "source": [
        "print(f\"\\033[92mTraining started from epoch {epoch + 1} to {num_epochs}.\\033[0m\")\n",
        "\n",
        "while epoch < num_epochs:\n",
        "    print(f\"\\n\\033[93mEpoch {epoch + 1}/{num_epochs}\\033[0m\")\n",
        "\n",
        "    \"\"\" TRAINING STEP \"\"\"\n",
        "    # Set the model to training mode.\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (images, landmarks, labels) in enumerate(train_loader):\n",
        "        print(f\"\\rBatch {i + 1}/{len(train_loader)} ({100 * (i + 1) / len(train_loader):.2f}%), Epoch Loss: {running_loss / len(train_loader):.4f}\", end='')\n",
        "\n",
        "        images, landmarks, labels = images.to(device), landmarks.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if model.combined == 'Image':\n",
        "            outputs = model(x=images)\n",
        "        elif model.combined == 'Landmark':\n",
        "            outputs = model(landmarks=landmarks)\n",
        "        elif model.combined == 'Combined':\n",
        "            outputs = model(x=images, landmarks=landmarks)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print()\n",
        "\n",
        "    \"\"\" VALIDATION STEP \"\"\"\n",
        "    # Set the model to evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, landmarks, labels) in enumerate(test_loader):\n",
        "            print(f\"\\rValidation Batch {i + 1}/{len(test_loader)} ({100 * (i + 1) / len(test_loader):.2f}%)\", end='')\n",
        "\n",
        "            images, landmarks, labels = images.to(device), landmarks.to(device), labels.to(device)\n",
        "            if model.combined == 'Image':\n",
        "                outputs = model(x=images)\n",
        "            elif model.combined == 'Landmark':\n",
        "                outputs = model(landmarks=landmarks)\n",
        "            elif model.combined == 'Combined':\n",
        "                outputs = model(x=images, landmarks=landmarks)\n",
        "\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(f\", Validation Accuracy: {correct / total:.4f}\")\n",
        "\n",
        "    epoch += 1\n",
        "\n",
        "    # Save the trained model for the epoch.\n",
        "    torch.save(model.state_dict(), f\"{model_dir}model/{timestamp}/epoch_{epoch}.pt\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cvproject",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
