{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 08:53:11.148354: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pd.read_json('new_data/lm_300wLP_anno_tr.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the X array.\n",
    "X = []\n",
    "for row in lm['landmarks_2d']:\n",
    "    \n",
    "    # Skip the row if it has less than 12 elements.\n",
    "    if len(row) < 12:\n",
    "        continue\n",
    "    \n",
    "    # Get the first 12 elements of the array.\n",
    "    row = row[:12]\n",
    "    \n",
    "    # Flatten the array.\n",
    "    row_ = np.array(row).reshape(12, 68 * 2)\n",
    "    X.append(row_)\n",
    "\n",
    "# Create the y array.\n",
    "y = []\n",
    "for row in lm['landmarks']:\n",
    "    \n",
    "    # Skip the row if it has less than 12 elements.\n",
    "    if len(row) < 12:\n",
    "        continue\n",
    "    \n",
    "    # Get only the first element.\n",
    "    row = row[0]\n",
    "    \n",
    "    # Flatten the array.\n",
    "    row_ = np.array(row).reshape(68 * 3)\n",
    "    y.append(row_)\n",
    "\n",
    "# Convert the lists to numpy arrays.\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=42)\n",
    "y_train, y_test = train_test_split(y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkModel(models.Model):\n",
    "    def __init__(self, in_, out_):\n",
    "        super(LandmarkModel, self).__init__()\n",
    "        self.lstm1 = layers.LSTM(64, return_sequences=True, input_shape=in_)\n",
    "        self.lstm2 = layers.LSTM(64)\n",
    "        self.dense = layers.Dense(out_, activation='linear')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.lstm1(inputs)\n",
    "        x = self.lstm2(x)\n",
    "        return self.dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the input and output shapes.\n",
    "in_ = X[0].shape\n",
    "out_ = y[0].shape[0]\n",
    "\n",
    "# Print the shapes.\n",
    "print(f'{X[0].shape=}, {y[0].shape=}')\n",
    "\n",
    "# Create the model.\n",
    "model = LandmarkModel(in_, out_)\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X[0].shape=(12, 136), y[0].shape=(204,)\n",
      "Epoch 1/50\n",
      "75/75 [==============================] - 10s 40ms/step - loss: 46841.5156 - val_loss: 45688.6094\n",
      "Epoch 2/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 44728.4570 - val_loss: 43753.4336\n",
      "Epoch 3/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 42902.2969 - val_loss: 42009.5938\n",
      "Epoch 4/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 41211.5234 - val_loss: 40368.2773\n",
      "Epoch 5/50\n",
      "75/75 [==============================] - 1s 12ms/step - loss: 39609.1719 - val_loss: 38803.5703\n",
      "Epoch 6/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 38076.9336 - val_loss: 37303.4180\n",
      "Epoch 7/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 36605.8438 - val_loss: 35860.9141\n",
      "Epoch 8/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 35188.3750 - val_loss: 34469.4023\n",
      "Epoch 9/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 33820.1484 - val_loss: 33126.0039\n",
      "Epoch 10/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 32500.0996 - val_loss: 31828.6855\n",
      "Epoch 11/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 31223.0840 - val_loss: 30573.4473\n",
      "Epoch 12/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 29987.9141 - val_loss: 29359.3281\n",
      "Epoch 13/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 28792.9121 - val_loss: 28184.7793\n",
      "Epoch 14/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 27636.7930 - val_loss: 27048.2930\n",
      "Epoch 15/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 26517.7031 - val_loss: 25947.8672\n",
      "Epoch 16/50\n",
      "75/75 [==============================] - 1s 17ms/step - loss: 25433.6133 - val_loss: 24882.0020\n",
      "Epoch 17/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 24384.0742 - val_loss: 23850.2676\n",
      "Epoch 18/50\n",
      "75/75 [==============================] - 1s 16ms/step - loss: 23368.3965 - val_loss: 22851.8691\n",
      "Epoch 19/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 22386.3496 - val_loss: 21886.9062\n",
      "Epoch 20/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 21436.5469 - val_loss: 20953.3184\n",
      "Epoch 21/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 20517.0469 - val_loss: 20049.4316\n",
      "Epoch 22/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 19628.6250 - val_loss: 19176.5879\n",
      "Epoch 23/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 18769.9961 - val_loss: 18332.9414\n",
      "Epoch 24/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17938.5742 - val_loss: 17516.4316\n",
      "Epoch 25/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 17135.6211 - val_loss: 16727.7285\n",
      "Epoch 26/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 16359.5967 - val_loss: 15965.7490\n",
      "Epoch 27/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 15610.9482 - val_loss: 15230.8857\n",
      "Epoch 28/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 14888.8389 - val_loss: 14522.2393\n",
      "Epoch 29/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 14192.5146 - val_loss: 13838.8799\n",
      "Epoch 30/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 13519.8711 - val_loss: 13178.7500\n",
      "Epoch 31/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 12871.4023 - val_loss: 12542.7217\n",
      "Epoch 32/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 12246.6221 - val_loss: 11930.1494\n",
      "Epoch 33/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 11644.5859 - val_loss: 11340.1582\n",
      "Epoch 34/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 11066.0557 - val_loss: 10773.2109\n",
      "Epoch 35/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 10509.2617 - val_loss: 10227.5742\n",
      "Epoch 36/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9973.9238 - val_loss: 9703.2129\n",
      "Epoch 37/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 9460.2402 - val_loss: 9200.5967\n",
      "Epoch 38/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 8966.3301 - val_loss: 8716.6123\n",
      "Epoch 39/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 8492.0908 - val_loss: 8252.5459\n",
      "Epoch 40/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 8037.7393 - val_loss: 7808.3921\n",
      "Epoch 41/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 7602.3823 - val_loss: 7382.4512\n",
      "Epoch 42/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 7185.5439 - val_loss: 6974.9487\n",
      "Epoch 43/50\n",
      "75/75 [==============================] - 1s 15ms/step - loss: 6787.2959 - val_loss: 6585.9805\n",
      "Epoch 44/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 6405.4453 - val_loss: 6213.0332\n",
      "Epoch 45/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 6041.0688 - val_loss: 5857.0850\n",
      "Epoch 46/50\n",
      "75/75 [==============================] - 1s 20ms/step - loss: 5692.9277 - val_loss: 5517.3203\n",
      "Epoch 47/50\n",
      "75/75 [==============================] - 2s 20ms/step - loss: 5360.7524 - val_loss: 5193.1426\n",
      "Epoch 48/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 5044.1719 - val_loss: 4884.4028\n",
      "Epoch 49/50\n",
      "75/75 [==============================] - 1s 13ms/step - loss: 4742.9277 - val_loss: 4590.8726\n",
      "Epoch 50/50\n",
      "75/75 [==============================] - 1s 14ms/step - loss: 4456.2046 - val_loss: 4311.5312\n"
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model.\n",
    "loss = model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
